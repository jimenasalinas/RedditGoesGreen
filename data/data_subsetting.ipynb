{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgT16vMRKWw1"
      },
      "source": [
        "## Subsetting Reddit Climate Data\n",
        "by *Santiago Segovia*\n",
        "\n",
        "Lines of code: ~ 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook subsets the data based on date and subreddits. The newly created structures are used to fine-tune a sentiment analysis model. Additionally, the code creates labels for `positive` and `negative` sentiment once we remove comments defined as neutral."
      ],
      "metadata": {
        "id": "1eIvBY0M1jo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Initial Set-up"
      ],
      "metadata": {
        "id": "2JrpuaCVYMTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aJDLrbUKWw5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b9aKDf2KWw7",
        "outputId": "1c8bab2b-2ac6-47ca-bda4-60f119022dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount GDrive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nETHK9N7Klph"
      },
      "outputs": [],
      "source": [
        "# Load data (takes 2 mins to load `comments`)\n",
        "data_path = \"/content/drive/Shareddrives/adv-ml-project/Data/\"\n",
        "comments = pd.read_csv(data_path + \"the-reddit-climate-change-dataset-comments.csv\")\n",
        "posts = pd.read_csv(data_path + \"the-reddit-climate-change-dataset-posts.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define how the subreddit subset will happen\n",
        "by_num_comments = False\n",
        "by_categories = not by_num_comments\n",
        "if by_categories:\n",
        "  categories_subset = ['collapse','futurology','canada','australia','the_donald']"
      ],
      "metadata": {
        "id": "R3Sy8u5CRuoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create date variable based on utc\n",
        "comments['date'] = pd.to_datetime(comments['created_utc'], unit='s')\n",
        "posts['date'] = pd.to_datetime(posts['created_utc'], unit='s')"
      ],
      "metadata": {
        "id": "gJRAu1e9RS7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a function to assign labels in the dataset. For this, we use the `sentiment` variable. We define the 0 value as neutrality:"
      ],
      "metadata": {
        "id": "Nsh4Bgpk7Hr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label\n",
        "def create_label(sentiment):\n",
        "    if sentiment < 0:\n",
        "        return 0\n",
        "    elif sentiment > 0:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "huJec0-yRVm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments['label'] = comments['sentiment'].apply(create_label)"
      ],
      "metadata": {
        "id": "oISaM5XhRbFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Data Subsetting"
      ],
      "metadata": {
        "id": "odg0E-1gYaq2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFcLWMDpSzRL",
        "outputId": "5c275089-37ba-4577-a416-f0daa0c69247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records in comments df: 4600698\n",
            "Number of records in posts df: 620908\n"
          ]
        }
      ],
      "source": [
        "initial_comments_shape = comments.shape\n",
        "initial_posts_shape = posts.shape\n",
        "print(\"Number of records in comments df:\", initial_comments_shape[0])\n",
        "print(\"Number of records in posts df:\", initial_posts_shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzxrPpHiKnYk"
      },
      "outputs": [],
      "source": [
        "# We keep columns we'll use in the analysis\n",
        "comments = comments[['subreddit.name','date','body','sentiment','label']]\n",
        "posts = posts[['subreddit.name','date','title']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuJE8-p0NJnN"
      },
      "outputs": [],
      "source": [
        "# Subset by date (keep every record from 2015 onwards)\n",
        "comments = comments[comments['date']>='2015-01-01']\n",
        "posts = posts[posts['date']>='2015-01-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ho7W3EHStML",
        "outputId": "fb34e260-98a7-4069-ce25-06476c9eea6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records in comments df: 4338011\n",
            " Reduction of 4.71 % vs. original\n",
            "Number of records in posts df: 566808\n",
            " Reduction of 7.71 % vs. original\n"
          ]
        }
      ],
      "source": [
        "mid_comments_shape = comments.shape\n",
        "mid_posts_shape = posts.shape\n",
        "print(\"Number of records in comments df:\", mid_comments_shape[0])\n",
        "print(\" Reduction of\", round((initial_comments_shape[0] - mid_comments_shape[0]) * 100 / initial_comments_shape[0] - 1,2), \"% vs. original\")\n",
        "print(\"Number of records in posts df:\", mid_posts_shape[0])\n",
        "print(\" Reduction of\", round((initial_posts_shape[0] - mid_posts_shape[0]) * 100 / initial_posts_shape[0] - 1,2), \"% vs. original\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset by label (remove neutrality)\n",
        "comments = comments[~comments['label'].isna()]"
      ],
      "metadata": {
        "id": "QB6sZtep8yJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mid_comments_shape = comments.shape\n",
        "print(\"Number of records in comments df:\", mid_comments_shape[0])\n",
        "print(\" Reduction of\", round((initial_comments_shape[0] - mid_comments_shape[0]) * 100 / initial_comments_shape[0] - 1,2), \"% vs. original\")"
      ],
      "metadata": {
        "id": "lAYX2tPA9DMh",
        "outputId": "553423da-67c5-45a2-bbfb-ee46df8cccbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records in comments df: 4013116\n",
            " Reduction of 11.77 % vs. original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOKQy48gNozo"
      },
      "outputs": [],
      "source": [
        "# Subset by number of subreddits that have 5000 or more comments\n",
        "def count_categories(categories):\n",
        "    category_counts = {}\n",
        "    for category in categories:\n",
        "        if category in category_counts:\n",
        "            category_counts[category] += 1\n",
        "        else:\n",
        "            category_counts[category] = 1\n",
        "\n",
        "    return list(category_counts.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CD_1QQJcOQEn"
      },
      "outputs": [],
      "source": [
        "subreddits = count_categories(comments['subreddit.name'])\n",
        "sorted_subreddits = sorted(subreddits, key=lambda x: x[1], reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nChmhM1gN8SI"
      },
      "outputs": [],
      "source": [
        "def drop_tuples_below_threshold(tuples_list, by_num_comments, by_categories,\n",
        "                                threshold=None, cat_to_keep=None):\n",
        "    if by_num_comments:\n",
        "        to_keep = []\n",
        "        cat_num = []\n",
        "        for name, count in tuples_list:\n",
        "            if count >= threshold:\n",
        "              to_keep.append(name)\n",
        "              cat_num.append((name, count))\n",
        "        return to_keep, cat_num\n",
        "    elif by_categories:\n",
        "        cat_num = []\n",
        "        for name, count in tuples_list:\n",
        "            if name in cat_to_keep:\n",
        "                cat_num.append((name, count))\n",
        "\n",
        "        return cat_to_keep, cat_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nokomd9GOXvx"
      },
      "outputs": [],
      "source": [
        "#Dropping subreddits based on condition\n",
        "if by_num_comments:\n",
        "    categories, counts_categories  = drop_tuples_below_threshold(sorted_subreddits, by_num_comments, by_categories, threshold=100000)\n",
        "else:\n",
        "    categories, counts_categories  = drop_tuples_below_threshold(sorted_subreddits, by_num_comments, by_categories,\n",
        "                                                             cat_to_keep=categories_subset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts_categories"
      ],
      "metadata": {
        "id": "Dev6nahIYlg2",
        "outputId": "52bc142a-0d41-42a2-93b5-5fc7ccee21ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('collapse', 88010),\n",
              " ('futurology', 83235),\n",
              " ('canada', 59037),\n",
              " ('australia', 46267),\n",
              " ('the_donald', 30492)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8703qWqR9cF"
      },
      "outputs": [],
      "source": [
        "comments = comments[comments['subreddit.name'].isin(categories)]\n",
        "posts = posts[posts['subreddit.name'].isin(categories)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VsiI1GqSMjr",
        "outputId": "f522ef9c-f94e-4d05-b3c0-b2b77e45f08c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records in comments df: 307041\n",
            " Reduction of 92.33 % vs. original\n",
            "Number of records in posts df: 18775\n",
            " Reduction of 95.98 % vs. original\n"
          ]
        }
      ],
      "source": [
        "end_comments_shape = comments.shape\n",
        "end_posts_shape = posts.shape\n",
        "print(\"Number of records in comments df:\", end_comments_shape[0])\n",
        "print(\" Reduction of\", round((initial_comments_shape[0] - end_comments_shape[0]) * 100 / initial_comments_shape[0] - 1,2),\"% vs. original\")\n",
        "print(\"Number of records in posts df:\", end_posts_shape[0])\n",
        "print(\" Reduction of\", round((initial_posts_shape[0] - end_posts_shape[0]) * 100 / initial_posts_shape[0] - 1,2),\"% vs. original\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Export Data"
      ],
      "metadata": {
        "id": "4AvJwcOUYvXZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nDVSh05HPBk"
      },
      "outputs": [],
      "source": [
        "# Export files\n",
        "import csv\n",
        "\n",
        "comments.reset_index(drop=True, inplace=True)\n",
        "posts.reset_index(drop=True, inplace=True)\n",
        "if by_num_comments:\n",
        "    comments.to_csv(data_path + '/by_threshold/comments_filtered.csv', quoting=csv.QUOTE_NONNUMERIC, index=False)\n",
        "    posts.to_csv(data_path + '/by_threshold/posts_filtered.csv', quoting=csv.QUOTE_NONNUMERIC, index=False)\n",
        "else:\n",
        "    comments.to_csv(data_path + '/by_category/comments_filtered.csv', quoting=csv.QUOTE_NONNUMERIC, index=False)\n",
        "    posts.to_csv(data_path + '/by_category/posts_filtered.csv', quoting=csv.QUOTE_NONNUMERIC, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}